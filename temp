import sys, os
CURRENT_PATH = '/home/arasu/FYP/lipreading_code/Training'

sys.path.insert(0, CURRENT_PATH)


from keras.optimizers import Adam
from keras.callbacks import TensorBoard, CSVLogger, ModelCheckpoint
from generators import BasicGenerator
from callbacks import Metrics
from curriculums import Curriculum
from decoders import Decoder
from helpers import labels_to_text
from spell import Spell
from model import LipNet
import numpy as np
import datetime

np.random.seed(55)

DATASET_DIR  = os.path.join(CURRENT_PATH, 'datasets')
OUTPUT_DIR   = os.path.join(CURRENT_PATH, 'results')
LOG_DIR      = os.path.join(CURRENT_PATH, 'logs')

PREDICT_GREEDY      = False
PREDICT_BEAM_WIDTH  = 200
PREDICT_DICTIONARY  = os.path.join(CURRENT_PATH,'dictionaries','grid.txt')

def curriculum_rules(epoch):
    return { 'sentence_length': -1, 'flip_probability': 0.5, 'jitter_probability': 0.05 }

run_name = datetime.datetime.now().strftime('%Y:%m:%d:%H:%M:%S')
run_name, start_epoch, stop_epoch, img_c, img_w, img_h, frames_n, absolute_max_string_len, minibatch_size = (run_name, 0, 5000, 3, 100, 50, 75, 32, 50)

curriculum = Curriculum(curriculum_rules)
lip_gen = BasicGenerator(dataset_path=DATASET_DIR,
                            minibatch_size=minibatch_size,
                            img_c=img_c, img_w=img_w, img_h=img_h, frames_n=frames_n,
                            absolute_max_string_len=absolute_max_string_len,
                            curriculum=curriculum, start_epoch=start_epoch).build()

lipnet = LipNet(img_c=img_c, img_w=img_w, img_h=img_h, frames_n=frames_n,
                        absolute_max_string_len=absolute_max_string_len, output_size=lip_gen.get_output_size())
#lipnet.summary()

adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)

# the loss calc occurs elsewhere, so use a dummy lambda func for the loss
lipnet.model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=adam)


spell = Spell(path=PREDICT_DICTIONARY)
decoder = Decoder(greedy=PREDICT_GREEDY, beam_width=PREDICT_BEAM_WIDTH,
                  postprocessors=[labels_to_text, spell.sentence])

try:
    os.makedirs(os.path.join(LOG_DIR, run_name), exist_ok=True)
except:
    pass

statistics  = Metrics(lipnet, lip_gen.next_val(), decoder, 256, minibatch_size, os.path.join(OUTPUT_DIR, run_name))
